{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moyang/.pyenv/versions/3.7.1/envs/amazon_project/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "asin                0\n",
       "title               0\n",
       "brand           19334\n",
       "Rating              0\n",
       "reviewerID          0\n",
       "reviewTime          0\n",
       "reviewText          0\n",
       "summary             0\n",
       "vote          1778221\n",
       "rank                0\n",
       "also_buy            0\n",
       "also_view           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/cleaned_df')\n",
    "# df = df.dropna(subset = ['summary' , 'reviewText'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary       0\n",
       "reviewText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['summary', 'reviewText']]\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps:\n",
    "* lowercase\n",
    "* numbers\n",
    "* punctuations\n",
    "* stopwords\n",
    "* lemmatizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'packages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2ce47169dd53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpackages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'packages'"
     ]
    }
   ],
   "source": [
    "from packages import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_punc(text):\n",
    "    for punc in string.punctuation:\n",
    "        text = text.replace(punc, '')\n",
    "    return text\n",
    "\n",
    "def remove_digit(text):\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    return text  \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word.lower() for word in word_tokenize(text) if not word in stop_words])\n",
    "    return text\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lst = [WordNetLemmatizer().lemmatize(word) for word in word_tokenize(text)]\n",
    "    return (' '.join(lst))\n",
    "\n",
    "\n",
    "data = data.applymap(remove_punc)\n",
    "data = data.applymap(remove_digit)\n",
    "data = data.applymap(remove_stopwords)\n",
    "data = data.applymap(lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessed data to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"./preprocessed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as lda\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_lda_model(data, n_components=2):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer().fit(data)\n",
    "    \n",
    "    data_vectorized = vectorizer.transform(data)\n",
    "     \n",
    "    lda_model = lda(n_components = n_components).fit(data_vectorized)\n",
    "    return (lda_model, vectorizer)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('star', 216206.33491629697), ('five', 176737.80546909876), ('one', 50764.31810980759), ('four', 35913.94048318108), ('work', 35678.964483053314), ('it', 22290.887775410592), ('three', 20662.347981813382), ('perfect', 16001.710268856034), ('two', 15146.883391477872), ('like', 13533.481795811238)]\n",
      "Topic 1:\n",
      "[('great', 106163.48674735877), ('game', 102804.84824138266), ('good', 58408.25463317011), ('fun', 42353.54729827685), ('love', 38051.499759474515), ('awesome', 32683.573688821623), ('best', 27377.363624394056), ('buy', 21881.531500314322), ('product', 20999.641478891503), ('the', 18785.26833593498)]\n"
     ]
    }
   ],
   "source": [
    "model, vectorizer = get_lda_model(data['summary'])\n",
    "print_topics(model, vectorizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
